{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 19 14:15:49 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   37C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "# from imgaug import augmenters as iaa\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-19 09:01:09--  https://storage.googleapis.com/kimata/datasets/face%20mask/dataset_full.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.4.80, 172.217.4.208, 142.250.191.112, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.4.80|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1198930675 (1.1G) [application/zip]\n",
      "Saving to: 'dataset_full.zip'\n",
      "\n",
      "dataset_full.zip    100%[===================>]   1.12G   128MB/s    in 10s     \n",
      "\n",
      "2022-06-19 09:01:20 (110 MB/s) - 'dataset_full.zip' saved [1198930675/1198930675]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://storage.googleapis.com/kimata/datasets/face%20mask/dataset_full.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Kaggle Feature engineering'   Zindi\t\t  face-mask-detection.ipynb\n",
      " Untitled.ipynb\t\t       dataset_full.zip   mnist_pca.npy\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile('dataset_full.zip', 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #Define image augmentation steps.\n",
    "# def apply_augmentation(input_image):\n",
    "#     aug_list = iaa.Sequential([\n",
    "#         iaa.SaltAndPepper(0.1),\n",
    "#         iaa.GammaContrast((0.8, 1.0), per_channel = True),\n",
    "#         iaa.AdditiveGaussianNoise(scale = (0, 0.2 * 255))\n",
    "#     ])\n",
    "    \n",
    "#     image_aug = aug_list(image = input_image)\n",
    "#     return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMAGES = 'dataset_full'\n",
    "BATCH_SIZE = 32\n",
    "CLASS_MODE = 'categorical'\n",
    "\n",
    "datagen_train = ImageDataGenerator(rescale = 1 / 255,\n",
    "                                  # preprocessing_function = apply_augmentation,\n",
    "                                  validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4162 images belonging to 3 classes.\n",
      "Found 1039 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen_train.flow_from_directory(PATH_TO_IMAGES, \n",
    "                                                   target_size = (300, 300),\n",
    "                                                   batch_size = BATCH_SIZE, \n",
    "                                                   class_mode = CLASS_MODE,\n",
    "                                                   subset = 'training')\n",
    "\n",
    "test_generator = datagen_train.flow_from_directory(PATH_TO_IMAGES,\n",
    "                                                 target_size = (300, 300),\n",
    "                                                 batch_size = BATCH_SIZE,\n",
    "                                                 class_mode = CLASS_MODE,\n",
    "                                                 subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use different pretrained models for classification.\n",
    "class KerasFactory():\n",
    "    #This class can be used to create a keras model and return it.\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def create_and_return_keras_model(self, model_name, num_classes, input_shape, \n",
    "                                     activation_func = 'softmax', transfer_learning = True):\n",
    "    \n",
    "        if (not isinstance(model_name, str)):\n",
    "            raise ValueError('Input model_name has the wrong datatype!')\n",
    "\n",
    "        if (not isinstance (num_classes, int)):\n",
    "            raise ValueError('Input num_classes has the wrong datatype.')\n",
    "\n",
    "        if (not isinstance (transfer_learning, bool)):\n",
    "            raise ValueError('Input transfer_learning has the wrong datatype.')\n",
    "\n",
    "        if (not isinstance (activation_func, str)):\n",
    "            raise ValueError('Input activation_func has the wrong datatype.')\n",
    "\n",
    "        weights = 'imagenet' if transfer_learning else None\n",
    "\n",
    "        if model_name == 'mobilenet_v2':\n",
    "            from tensorflow.keras.applications import MobileNetV2\n",
    "            model = MobileNetV2(weights = weights, include_top = False, input_shape = input_shape)\n",
    "\n",
    "        elif model_name == 'mobilenet_v3':\n",
    "            from tensorflow.keras.applications import MobileNetV3Small\n",
    "            model = MobileNetV3Small(include_top = False, weights = weights, input_shape = input_shape)\n",
    "            \n",
    "        elif model_name == 'densenet_121':\n",
    "            from tensorflow.keras.applications.densenet import DenseNet121\n",
    "            model = DenseNet121(include_top = False, weights = weights, input_shape = input_shape)\n",
    "            \n",
    "        elif model_name == 'resnet_50':\n",
    "            from tensorflow.keras.applications.resnet50 import ResNet50 \n",
    "            model = ResNet50(include_top = False, weights = weights, input_shape = input_shape)\n",
    "            \n",
    "        else:\n",
    "            from classification_models.tfkeras import Classifiers\n",
    "            net, _ = Classifiers.get(model_name)\n",
    "            model = net(input_shape = input_shape, include_top = False, weigts = weights)\n",
    "        \n",
    "        \n",
    "        #Add a global spatial averaging pooling layer to decrease the risk of overfitting and plot the class activation maps.\n",
    "        output = model.output\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(output)\n",
    "\n",
    "        #Add a layer of dropout to also avoid overfitting.\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "        #Add a fully connected layer.\n",
    "        x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
    "\n",
    "        #Add another layer of dropout.\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "        #Output layer.\n",
    "        predictions = tf.keras.layers.Dense(num_classes, activation = activation_func)(x)\n",
    "\n",
    "        #Create the model.\n",
    "        model = tf.keras.Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test keras factory.\n",
    "factory = KerasFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training densenet_121...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29084464/29084464 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 120s 760ms/step - loss: 0.1884 - accuracy: 0.9270 - auc: 0.9902 - f1_score: 0.9282 - val_loss: 0.1961 - val_accuracy: 0.9211 - val_auc: 0.9891 - val_f1_score: 0.9235\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 91s 694ms/step - loss: 0.0511 - accuracy: 0.9827 - auc: 0.9989 - f1_score: 0.9824 - val_loss: 0.1026 - val_accuracy: 0.9702 - val_auc: 0.9949 - val_f1_score: 0.9695\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 92s 701ms/step - loss: 0.0433 - accuracy: 0.9825 - auc: 0.9995 - f1_score: 0.9831 - val_loss: 0.0564 - val_accuracy: 0.9808 - val_auc: 0.9985 - val_f1_score: 0.9805\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 93s 706ms/step - loss: 0.0352 - accuracy: 0.9887 - auc: 0.9995 - f1_score: 0.9888 - val_loss: 0.0230 - val_accuracy: 0.9904 - val_auc: 0.9994 - val_f1_score: 0.9903\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0197 - accuracy: 0.9928 - auc: 0.9999 - f1_score: 0.9927 - val_loss: 0.0208 - val_accuracy: 0.9933 - val_auc: 0.9999 - val_f1_score: 0.9933\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0107 - accuracy: 0.9966 - auc: 0.9998 - f1_score: 0.9966 - val_loss: 0.0233 - val_accuracy: 0.9913 - val_auc: 0.9992 - val_f1_score: 0.9913\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0151 - accuracy: 0.9950 - auc: 0.9998 - f1_score: 0.9950 - val_loss: 0.0168 - val_accuracy: 0.9971 - val_auc: 0.9992 - val_f1_score: 0.9971\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0083 - accuracy: 0.9976 - auc: 0.9998 - f1_score: 0.9976 - val_loss: 0.0267 - val_accuracy: 0.9875 - val_auc: 0.9998 - val_f1_score: 0.9873\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0088 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - val_loss: 0.0190 - val_accuracy: 0.9933 - val_auc: 0.9992 - val_f1_score: 0.9933\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0146 - accuracy: 0.9957 - auc: 0.9998 - f1_score: 0.9957 - val_loss: 0.0734 - val_accuracy: 0.9808 - val_auc: 0.9953 - val_f1_score: 0.9804\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0161 - accuracy: 0.9952 - auc: 0.9994 - f1_score: 0.9952 - val_loss: 0.1095 - val_accuracy: 0.9740 - val_auc: 0.9949 - val_f1_score: 0.9729\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0205 - accuracy: 0.9935 - auc: 0.9995 - f1_score: 0.9934 - val_loss: 0.0142 - val_accuracy: 0.9962 - val_auc: 0.9992 - val_f1_score: 0.9961\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0275 - accuracy: 0.9921 - auc: 0.9991 - f1_score: 0.9921 - val_loss: 0.0234 - val_accuracy: 0.9904 - val_auc: 0.9998 - val_f1_score: 0.9904\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0212 - accuracy: 0.9930 - auc: 0.9994 - f1_score: 0.9930 - val_loss: 0.2772 - val_accuracy: 0.9355 - val_auc: 0.9827 - val_f1_score: 0.9275\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0331 - accuracy: 0.9892 - auc: 0.9992 - f1_score: 0.9893 - val_loss: 0.0315 - val_accuracy: 0.9817 - val_auc: 0.9997 - val_f1_score: 0.9817\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0210 - accuracy: 0.9933 - auc: 0.9997 - f1_score: 0.9933 - val_loss: 0.0180 - val_accuracy: 0.9913 - val_auc: 0.9999 - val_f1_score: 0.9914\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0120 - accuracy: 0.9964 - auc: 0.9998 - f1_score: 0.9964 - val_loss: 0.0284 - val_accuracy: 0.9913 - val_auc: 0.9991 - val_f1_score: 0.9908\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0116 - accuracy: 0.9964 - auc: 0.9998 - f1_score: 0.9964 - val_loss: 0.0219 - val_accuracy: 0.9933 - val_auc: 0.9992 - val_f1_score: 0.9933\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0109 - accuracy: 0.9957 - auc: 0.9998 - f1_score: 0.9956 - val_loss: 0.0232 - val_accuracy: 0.9923 - val_auc: 0.9999 - val_f1_score: 0.9923\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0084 - accuracy: 0.9971 - auc: 1.0000 - f1_score: 0.9971 - val_loss: 0.0376 - val_accuracy: 0.9885 - val_auc: 0.9977 - val_f1_score: 0.9885\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0052 - accuracy: 0.9986 - auc: 1.0000 - f1_score: 0.9986 - val_loss: 0.0287 - val_accuracy: 0.9904 - val_auc: 0.9984 - val_f1_score: 0.9904\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0022 - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9993 - val_loss: 0.0321 - val_accuracy: 0.9904 - val_auc: 0.9992 - val_f1_score: 0.9904\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0033 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9989 - val_loss: 0.0394 - val_accuracy: 0.9904 - val_auc: 0.9984 - val_f1_score: 0.9904\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - f1_score: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9923 - val_auc: 0.9985 - val_f1_score: 0.9923\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0191 - accuracy: 0.9945 - auc: 0.9992 - f1_score: 0.9945 - val_loss: 0.0565 - val_accuracy: 0.9788 - val_auc: 0.9979 - val_f1_score: 0.9791\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0270 - accuracy: 0.9935 - auc: 0.9989 - f1_score: 0.9934 - val_loss: 0.0713 - val_accuracy: 0.9721 - val_auc: 0.9988 - val_f1_score: 0.9721\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0290 - accuracy: 0.9899 - auc: 0.9996 - f1_score: 0.9899 - val_loss: 0.0536 - val_accuracy: 0.9779 - val_auc: 0.9993 - val_f1_score: 0.9783\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 93s 706ms/step - loss: 0.0114 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - val_loss: 0.0514 - val_accuracy: 0.9827 - val_auc: 0.9987 - val_f1_score: 0.9821\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 93s 706ms/step - loss: 0.0135 - accuracy: 0.9952 - auc: 0.9999 - f1_score: 0.9952 - val_loss: 0.0337 - val_accuracy: 0.9875 - val_auc: 0.9991 - val_f1_score: 0.9875\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 93s 705ms/step - loss: 0.0068 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9974 - val_loss: 0.0333 - val_accuracy: 0.9885 - val_auc: 0.9984 - val_f1_score: 0.9885\n",
      "Start training resnet_50...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 2s 0us/step\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 106s 735ms/step - loss: 0.1490 - accuracy: 0.9411 - auc: 0.9939 - f1_score: 0.9407 - val_loss: 3.0864 - val_accuracy: 0.6237 - val_auc: 0.7178 - val_f1_score: 0.4791\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0315 - accuracy: 0.9901 - auc: 0.9995 - f1_score: 0.9899 - val_loss: 2.2260 - val_accuracy: 0.6237 - val_auc: 0.6829 - val_f1_score: 0.4791\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0275 - accuracy: 0.9894 - auc: 0.9998 - f1_score: 0.9894 - val_loss: 1.5629 - val_accuracy: 0.6237 - val_auc: 0.7126 - val_f1_score: 0.4791\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0281 - accuracy: 0.9897 - auc: 0.9994 - f1_score: 0.9894 - val_loss: 3.2078 - val_accuracy: 0.6237 - val_auc: 0.7205 - val_f1_score: 0.4791\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0324 - accuracy: 0.9906 - auc: 0.9989 - f1_score: 0.9904 - val_loss: 2.0490 - val_accuracy: 0.7584 - val_auc: 0.8340 - val_f1_score: 0.6947\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0407 - accuracy: 0.9856 - auc: 0.9990 - f1_score: 0.9854 - val_loss: 2.4234 - val_accuracy: 0.6246 - val_auc: 0.7639 - val_f1_score: 0.4813\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0170 - accuracy: 0.9933 - auc: 0.9996 - f1_score: 0.9931 - val_loss: 0.9227 - val_accuracy: 0.7498 - val_auc: 0.9149 - val_f1_score: 0.6914\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0113 - accuracy: 0.9952 - auc: 1.0000 - f1_score: 0.9952 - val_loss: 0.0964 - val_accuracy: 0.9615 - val_auc: 0.9963 - val_f1_score: 0.9626\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0132 - accuracy: 0.9962 - auc: 0.9996 - f1_score: 0.9962 - val_loss: 0.0742 - val_accuracy: 0.9836 - val_auc: 0.9958 - val_f1_score: 0.9836\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0133 - accuracy: 0.9959 - auc: 0.9998 - f1_score: 0.9959 - val_loss: 0.0328 - val_accuracy: 0.9894 - val_auc: 0.9990 - val_f1_score: 0.9894\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0218 - accuracy: 0.9940 - auc: 0.9993 - f1_score: 0.9936 - val_loss: 0.0306 - val_accuracy: 0.9923 - val_auc: 0.9984 - val_f1_score: 0.9923\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0173 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9939 - val_loss: 0.0977 - val_accuracy: 0.9759 - val_auc: 0.9948 - val_f1_score: 0.9766\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0082 - accuracy: 0.9971 - auc: 1.0000 - f1_score: 0.9971 - val_loss: 0.0399 - val_accuracy: 0.9885 - val_auc: 0.9990 - val_f1_score: 0.9883\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0064 - accuracy: 0.9983 - auc: 0.9998 - f1_score: 0.9983 - val_loss: 0.0358 - val_accuracy: 0.9913 - val_auc: 0.9970 - val_f1_score: 0.9913\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0247 - accuracy: 0.9952 - auc: 0.9990 - f1_score: 0.9951 - val_loss: 0.1480 - val_accuracy: 0.9374 - val_auc: 0.9930 - val_f1_score: 0.9297\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0252 - accuracy: 0.9930 - auc: 0.9996 - f1_score: 0.9928 - val_loss: 0.2256 - val_accuracy: 0.9076 - val_auc: 0.9859 - val_f1_score: 0.8881\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0325 - accuracy: 0.9897 - auc: 0.9995 - f1_score: 0.9897 - val_loss: 0.0343 - val_accuracy: 0.9856 - val_auc: 0.9997 - val_f1_score: 0.9859\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 93s 713ms/step - loss: 0.0488 - accuracy: 0.9849 - auc: 0.9986 - f1_score: 0.9851 - val_loss: 0.0482 - val_accuracy: 0.9827 - val_auc: 0.9987 - val_f1_score: 0.9843\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0143 - accuracy: 0.9940 - auc: 0.9999 - f1_score: 0.9940 - val_loss: 0.0369 - val_accuracy: 0.9894 - val_auc: 0.9991 - val_f1_score: 0.9894\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0103 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - val_loss: 0.0224 - val_accuracy: 0.9904 - val_auc: 0.9992 - val_f1_score: 0.9904\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0038 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9990 - val_loss: 0.0270 - val_accuracy: 0.9913 - val_auc: 0.9998 - val_f1_score: 0.9913\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0078 - accuracy: 0.9976 - auc: 0.9998 - f1_score: 0.9976 - val_loss: 0.0835 - val_accuracy: 0.9836 - val_auc: 0.9955 - val_f1_score: 0.9833\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0123 - accuracy: 0.9962 - auc: 0.9998 - f1_score: 0.9962 - val_loss: 0.0299 - val_accuracy: 0.9865 - val_auc: 0.9991 - val_f1_score: 0.9864\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 93s 707ms/step - loss: 0.0071 - accuracy: 0.9966 - auc: 1.0000 - f1_score: 0.9966 - val_loss: 0.0284 - val_accuracy: 0.9933 - val_auc: 0.9992 - val_f1_score: 0.9932\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0066 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9974 - val_loss: 0.0267 - val_accuracy: 0.9913 - val_auc: 0.9991 - val_f1_score: 0.9913\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 93s 709ms/step - loss: 0.0065 - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9983 - val_loss: 0.0345 - val_accuracy: 0.9923 - val_auc: 0.9984 - val_f1_score: 0.9924\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0306 - accuracy: 0.9906 - auc: 0.9991 - f1_score: 0.9906 - val_loss: 0.0599 - val_accuracy: 0.9788 - val_auc: 0.9985 - val_f1_score: 0.9783\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 93s 708ms/step - loss: 0.0065 - accuracy: 0.9981 - auc: 1.0000 - f1_score: 0.9981 - val_loss: 0.0479 - val_accuracy: 0.9788 - val_auc: 0.9995 - val_f1_score: 0.9781\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 93s 710ms/step - loss: 0.0032 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9990 - val_loss: 0.0228 - val_accuracy: 0.9942 - val_auc: 0.9992 - val_f1_score: 0.9942\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 93s 711ms/step - loss: 0.0018 - accuracy: 0.9998 - auc: 1.0000 - f1_score: 0.9998 - val_loss: 0.0267 - val_accuracy: 0.9933 - val_auc: 0.9985 - val_f1_score: 0.9933\n",
      "Start training mobilenet_v2...\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 71s 492ms/step - loss: 0.2381 - accuracy: 0.9070 - auc: 0.9844 - f1_score: 0.9047 - val_loss: 1.8810 - val_accuracy: 0.6497 - val_auc: 0.7246 - val_f1_score: 0.5382\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 62s 475ms/step - loss: 0.0514 - accuracy: 0.9808 - auc: 0.9993 - f1_score: 0.9810 - val_loss: 1.6781 - val_accuracy: 0.6477 - val_auc: 0.7918 - val_f1_score: 0.5335\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 63s 479ms/step - loss: 0.0378 - accuracy: 0.9880 - auc: 0.9995 - f1_score: 0.9880 - val_loss: 1.7083 - val_accuracy: 0.6275 - val_auc: 0.7424 - val_f1_score: 0.4878\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 62s 469ms/step - loss: 0.0281 - accuracy: 0.9897 - auc: 0.9997 - f1_score: 0.9897 - val_loss: 1.5623 - val_accuracy: 0.6449 - val_auc: 0.8437 - val_f1_score: 0.5249\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 62s 473ms/step - loss: 0.0169 - accuracy: 0.9942 - auc: 0.9996 - f1_score: 0.9942 - val_loss: 3.4356 - val_accuracy: 0.6237 - val_auc: 0.7371 - val_f1_score: 0.4791\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 63s 478ms/step - loss: 0.0303 - accuracy: 0.9906 - auc: 0.9996 - f1_score: 0.9907 - val_loss: 3.0638 - val_accuracy: 0.6285 - val_auc: 0.7560 - val_f1_score: 0.4900\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 62s 474ms/step - loss: 0.0085 - accuracy: 0.9974 - auc: 0.9998 - f1_score: 0.9974 - val_loss: 2.9195 - val_accuracy: 0.6343 - val_auc: 0.7666 - val_f1_score: 0.5028\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 63s 477ms/step - loss: 0.0070 - accuracy: 0.9976 - auc: 1.0000 - f1_score: 0.9976 - val_loss: 3.1877 - val_accuracy: 0.6352 - val_auc: 0.7536 - val_f1_score: 0.5046\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 62s 473ms/step - loss: 0.0081 - accuracy: 0.9976 - auc: 1.0000 - f1_score: 0.9976 - val_loss: 1.1612 - val_accuracy: 0.6891 - val_auc: 0.8816 - val_f1_score: 0.6104\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 62s 473ms/step - loss: 0.0091 - accuracy: 0.9976 - auc: 0.9998 - f1_score: 0.9976 - val_loss: 0.5819 - val_accuracy: 0.8248 - val_auc: 0.9313 - val_f1_score: 0.7810\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 62s 474ms/step - loss: 0.0232 - accuracy: 0.9930 - auc: 0.9998 - f1_score: 0.9932 - val_loss: 1.0375 - val_accuracy: 0.8219 - val_auc: 0.8929 - val_f1_score: 0.7624\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 62s 471ms/step - loss: 0.0143 - accuracy: 0.9962 - auc: 0.9998 - f1_score: 0.9959 - val_loss: 0.4131 - val_accuracy: 0.8585 - val_auc: 0.9591 - val_f1_score: 0.8011\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 63s 478ms/step - loss: 0.0161 - accuracy: 0.9945 - auc: 0.9997 - f1_score: 0.9944 - val_loss: 1.3215 - val_accuracy: 0.5419 - val_auc: 0.7791 - val_f1_score: 0.5057\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 63s 478ms/step - loss: 0.0158 - accuracy: 0.9945 - auc: 0.9996 - f1_score: 0.9945 - val_loss: 0.5111 - val_accuracy: 0.8778 - val_auc: 0.9700 - val_f1_score: 0.8344\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 62s 477ms/step - loss: 0.0159 - accuracy: 0.9964 - auc: 0.9996 - f1_score: 0.9964 - val_loss: 0.3266 - val_accuracy: 0.8874 - val_auc: 0.9742 - val_f1_score: 0.8578\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 63s 478ms/step - loss: 0.0162 - accuracy: 0.9959 - auc: 0.9997 - f1_score: 0.9958 - val_loss: 0.1629 - val_accuracy: 0.9394 - val_auc: 0.9928 - val_f1_score: 0.9334\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 63s 481ms/step - loss: 0.0058 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - val_loss: 0.3450 - val_accuracy: 0.8835 - val_auc: 0.9842 - val_f1_score: 0.8468\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 63s 477ms/step - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - f1_score: 1.0000 - val_loss: 0.2053 - val_accuracy: 0.9172 - val_auc: 0.9905 - val_f1_score: 0.9021\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 63s 480ms/step - loss: 0.0127 - accuracy: 0.9971 - auc: 0.9998 - f1_score: 0.9971 - val_loss: 0.4187 - val_accuracy: 0.8441 - val_auc: 0.9657 - val_f1_score: 0.8319\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 63s 479ms/step - loss: 0.0062 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9977 - val_loss: 0.6195 - val_accuracy: 0.8075 - val_auc: 0.9533 - val_f1_score: 0.7707\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 62s 477ms/step - loss: 0.0249 - accuracy: 0.9926 - auc: 0.9993 - f1_score: 0.9926 - val_loss: 0.3088 - val_accuracy: 0.9201 - val_auc: 0.9768 - val_f1_score: 0.9124\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 63s 479ms/step - loss: 0.0063 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - val_loss: 0.4362 - val_accuracy: 0.8980 - val_auc: 0.9646 - val_f1_score: 0.8900\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 63s 476ms/step - loss: 0.0018 - accuracy: 0.9998 - auc: 1.0000 - f1_score: 0.9998 - val_loss: 0.2705 - val_accuracy: 0.9307 - val_auc: 0.9819 - val_f1_score: 0.9274\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 63s 476ms/step - loss: 0.0014 - accuracy: 0.9998 - auc: 1.0000 - f1_score: 0.9998 - val_loss: 0.2491 - val_accuracy: 0.9326 - val_auc: 0.9859 - val_f1_score: 0.9283\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 63s 478ms/step - loss: 0.0058 - accuracy: 0.9990 - auc: 0.9998 - f1_score: 0.9990 - val_loss: 0.1537 - val_accuracy: 0.9509 - val_auc: 0.9930 - val_f1_score: 0.9472\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 62s 474ms/step - loss: 0.0029 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9989 - val_loss: 0.1669 - val_accuracy: 0.9538 - val_auc: 0.9907 - val_f1_score: 0.9520\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 63s 476ms/step - loss: 0.0013 - accuracy: 0.9998 - auc: 1.0000 - f1_score: 0.9998 - val_loss: 0.1406 - val_accuracy: 0.9586 - val_auc: 0.9929 - val_f1_score: 0.9564\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 62s 474ms/step - loss: 0.0016 - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9995 - val_loss: 0.1013 - val_accuracy: 0.9740 - val_auc: 0.9949 - val_f1_score: 0.9731\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 64s 483ms/step - loss: 5.9532e-04 - accuracy: 0.9998 - auc: 1.0000 - f1_score: 0.9998 - val_loss: 0.0745 - val_accuracy: 0.9817 - val_auc: 0.9975 - val_f1_score: 0.9816\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 62s 471ms/step - loss: 0.0124 - accuracy: 0.9971 - auc: 0.9993 - f1_score: 0.9970 - val_loss: 0.2239 - val_accuracy: 0.9480 - val_auc: 0.9859 - val_f1_score: 0.9499\n",
      "Start training mobilenet_v3...\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
      "4334752/4334752 [==============================] - 0s 0us/step\n",
      "Epoch 1/30\n",
      "131/131 [==============================] - 65s 454ms/step - loss: 0.5982 - accuracy: 0.7537 - auc: 0.9051 - f1_score: 0.7183 - val_loss: 1.0097 - val_accuracy: 0.6237 - val_auc: 0.7079 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.1650 - accuracy: 0.9426 - auc: 0.9932 - f1_score: 0.9408 - val_loss: 0.9505 - val_accuracy: 0.6237 - val_auc: 0.7166 - val_f1_score: 0.4791\n",
      "Epoch 3/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 0.0944 - accuracy: 0.9656 - auc: 0.9972 - f1_score: 0.9650 - val_loss: 1.0302 - val_accuracy: 0.6237 - val_auc: 0.6943 - val_f1_score: 0.0244\n",
      "Epoch 4/30\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 0.0552 - accuracy: 0.9810 - auc: 0.9992 - f1_score: 0.9810 - val_loss: 1.0148 - val_accuracy: 0.6237 - val_auc: 0.6817 - val_f1_score: 0.4791\n",
      "Epoch 5/30\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 0.0598 - accuracy: 0.9815 - auc: 0.9986 - f1_score: 0.9816 - val_loss: 0.9524 - val_accuracy: 0.6237 - val_auc: 0.6812 - val_f1_score: 0.4791\n",
      "Epoch 6/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0358 - accuracy: 0.9875 - auc: 0.9995 - f1_score: 0.9876 - val_loss: 0.9631 - val_accuracy: 0.6237 - val_auc: 0.6580 - val_f1_score: 0.4791\n",
      "Epoch 7/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0348 - accuracy: 0.9880 - auc: 0.9996 - f1_score: 0.9881 - val_loss: 1.0265 - val_accuracy: 0.6237 - val_auc: 0.6584 - val_f1_score: 0.4791\n",
      "Epoch 8/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 0.0265 - accuracy: 0.9904 - auc: 0.9996 - f1_score: 0.9903 - val_loss: 0.9464 - val_accuracy: 0.6237 - val_auc: 0.6716 - val_f1_score: 0.4791\n",
      "Epoch 9/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 0.0309 - accuracy: 0.9909 - auc: 0.9995 - f1_score: 0.9911 - val_loss: 0.9434 - val_accuracy: 0.6237 - val_auc: 0.7043 - val_f1_score: 0.4791\n",
      "Epoch 10/30\n",
      "131/131 [==============================] - 58s 444ms/step - loss: 0.0181 - accuracy: 0.9940 - auc: 0.9999 - f1_score: 0.9942 - val_loss: 1.0264 - val_accuracy: 0.6237 - val_auc: 0.6922 - val_f1_score: 0.0133\n",
      "Epoch 11/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0136 - accuracy: 0.9964 - auc: 0.9999 - f1_score: 0.9964 - val_loss: 1.0047 - val_accuracy: 0.6237 - val_auc: 0.6796 - val_f1_score: 0.0114\n",
      "Epoch 12/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0171 - accuracy: 0.9938 - auc: 0.9999 - f1_score: 0.9936 - val_loss: 0.9621 - val_accuracy: 0.6237 - val_auc: 0.6897 - val_f1_score: 0.4787\n",
      "Epoch 13/30\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 0.0078 - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9969 - val_loss: 0.9703 - val_accuracy: 0.6237 - val_auc: 0.6775 - val_f1_score: 0.4791\n",
      "Epoch 14/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0069 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - val_loss: 0.9519 - val_accuracy: 0.6237 - val_auc: 0.6697 - val_f1_score: 0.4791\n",
      "Epoch 15/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0093 - accuracy: 0.9971 - auc: 1.0000 - f1_score: 0.9971 - val_loss: 0.9371 - val_accuracy: 0.6237 - val_auc: 0.7289 - val_f1_score: 0.4791\n",
      "Epoch 16/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0125 - accuracy: 0.9952 - auc: 0.9999 - f1_score: 0.9952 - val_loss: 1.0656 - val_accuracy: 0.6237 - val_auc: 0.6735 - val_f1_score: 0.4791\n",
      "Epoch 17/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0138 - accuracy: 0.9954 - auc: 0.9999 - f1_score: 0.9954 - val_loss: 1.5413 - val_accuracy: 0.6237 - val_auc: 0.6674 - val_f1_score: 0.4791\n",
      "Epoch 18/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 0.0066 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - val_loss: 1.6130 - val_accuracy: 0.6237 - val_auc: 0.6602 - val_f1_score: 0.4791\n",
      "Epoch 19/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0081 - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9978 - val_loss: 1.5684 - val_accuracy: 0.6237 - val_auc: 0.6769 - val_f1_score: 0.4791\n",
      "Epoch 20/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0045 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9990 - val_loss: 2.3837 - val_accuracy: 0.6237 - val_auc: 0.7226 - val_f1_score: 0.4791\n",
      "Epoch 21/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0095 - accuracy: 0.9971 - auc: 0.9999 - f1_score: 0.9970 - val_loss: 1.2338 - val_accuracy: 0.6237 - val_auc: 0.6689 - val_f1_score: 0.4791\n",
      "Epoch 22/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 0.0131 - accuracy: 0.9964 - auc: 0.9996 - f1_score: 0.9964 - val_loss: 1.3360 - val_accuracy: 0.6237 - val_auc: 0.6879 - val_f1_score: 0.4791\n",
      "Epoch 23/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0107 - accuracy: 0.9971 - auc: 0.9998 - f1_score: 0.9971 - val_loss: 1.2041 - val_accuracy: 0.6622 - val_auc: 0.8244 - val_f1_score: 0.5571\n",
      "Epoch 24/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0079 - accuracy: 0.9983 - auc: 0.9998 - f1_score: 0.9983 - val_loss: 0.7408 - val_accuracy: 0.7690 - val_auc: 0.9245 - val_f1_score: 0.7244\n",
      "Epoch 25/30\n",
      "131/131 [==============================] - 58s 441ms/step - loss: 0.0069 - accuracy: 0.9974 - auc: 1.0000 - f1_score: 0.9974 - val_loss: 1.4588 - val_accuracy: 0.6237 - val_auc: 0.7226 - val_f1_score: 0.4791\n",
      "Epoch 26/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0055 - accuracy: 0.9981 - auc: 1.0000 - f1_score: 0.9982 - val_loss: 1.5322 - val_accuracy: 0.6362 - val_auc: 0.8097 - val_f1_score: 0.5069\n",
      "Epoch 27/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0035 - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9990 - val_loss: 2.3245 - val_accuracy: 0.4966 - val_auc: 0.7043 - val_f1_score: 0.5227\n",
      "Epoch 28/30\n",
      "131/131 [==============================] - 58s 439ms/step - loss: 0.0032 - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9988 - val_loss: 1.5650 - val_accuracy: 0.6064 - val_auc: 0.7993 - val_f1_score: 0.6378\n",
      "Epoch 29/30\n",
      "131/131 [==============================] - 58s 440ms/step - loss: 9.7170e-04 - accuracy: 1.0000 - auc: 1.0000 - f1_score: 1.0000 - val_loss: 1.2420 - val_accuracy: 0.6872 - val_auc: 0.8559 - val_f1_score: 0.7171\n",
      "Epoch 30/30\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 0.0030 - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9993 - val_loss: 1.2004 - val_accuracy: 0.6862 - val_auc: 0.8590 - val_f1_score: 0.7223\n"
     ]
    }
   ],
   "source": [
    "encoder_list = ['densenet_121', 'resnet_50', 'mobilenet_v2', 'mobilenet_v3']\n",
    "num_epochs = 30\n",
    "\n",
    "for encoder in encoder_list:\n",
    "    print(f'Start training {encoder}...')\n",
    "    model = factory.create_and_return_keras_model(encoder, \n",
    "                                                 num_classes = 3,\n",
    "                                                 input_shape = (800, 600, 3),\n",
    "                                                 activation_func = 'softmax',\n",
    "                                                 transfer_learning = True)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "    \n",
    "    #Define metrics.\n",
    "    metrics_list = [\n",
    "        tf.keras.metrics.CategoricalAccuracy(name = 'accuracy'),\n",
    "        tf.keras.metrics.AUC(name = 'auc'),\n",
    "        tfa.metrics.F1Score(num_classes = 3, average = 'weighted', threshold = 0.5)\n",
    "    ]\n",
    "    \n",
    "    #Tensorboard callback.\n",
    "    tb_callback = TensorBoard(log_dir = f'logs/{encoder}')\n",
    "    \n",
    "    #Compile model.\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = metrics_list)\n",
    "    \n",
    "    #Fit the model.\n",
    "    with tf.device('GPU:0'):\n",
    "        model.fit(train_generator, epochs = num_epochs, verbose = 1,validation_data = test_generator, callbacks = [tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/Structured data/logs_full.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compress the logs file and download it.\n",
    "import shutil\n",
    "shutil.make_archive('logs_full', 'zip', 'logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
